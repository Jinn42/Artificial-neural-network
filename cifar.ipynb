{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN vs MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, \\\n",
    "BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.utils import resample\n",
    "#from utils_gpu import pick_gpu_lowest_memory\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set session\n",
    "config_1 = tf.ConfigProto()\n",
    "gpu_fraction_1 = float(os.environ.get('GPU_LIMIT_1', 0.2))\n",
    "#gpu_fraction_1 = float(os.environ.get('GPU_LIMIT_1', 0.99))\n",
    "config_1.gpu_options.per_process_gpu_memory_fraction = gpu_fraction_1\n",
    "\n",
    "sess_1 = tf.Session(config=config_1)\n",
    "sess_1.run(tf.global_variables_initializer())\n",
    "K.set_session(sess_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_original():\n",
    "    #READ DATA FRAME\n",
    "    (full_x_train, full_y_train), (full_x_test, full_y_test) = cifar10.load_data()\n",
    "    full_x_train = full_x_train.astype('float32')\n",
    "    \n",
    "    #z-score\n",
    "    mean = np.mean(full_x_train,axis=(0,1,2,3))\n",
    "    std = np.std(full_x_train,axis=(0,1,2,3))\n",
    "    full_x_train = (full_x_train-mean)/(std+1e-7)\n",
    "    full_x_test = (full_x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    return (full_x_train, full_y_train), (full_x_test, full_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_x_train, full_y_train), (full_x_test, full_y_test) = read_data_original()\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "full_y_train = np_utils.to_categorical(full_y_train,num_classes)\n",
    "full_y_test = np_utils.to_categorical(full_y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=5,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=5,\n",
    "        channel_shift_range=0.1,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen.fit(full_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(100, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(32,32,3)))\n",
    "model.add(Conv2D(100, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(200, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(200, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "\n",
    "model.add(Conv2D(400, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(400, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(800, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(800, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Dropout(0.125))\n",
    "model.add(Dense(2000))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation=\"softmax\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 32, 32, 100)       2800      \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 32, 32, 100)       90100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32, 32, 100)       400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 16, 16, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 16, 16, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 200)       180200    \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 16, 16, 200)       360200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 200)       800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 400)         720400    \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 8, 8, 400)         1440400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 400)         1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 4, 4, 400)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4, 4, 400)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 4, 4, 800)         2880800   \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 4, 4, 800)         5760800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4, 4, 800)         3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 2, 2, 800)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              1602000   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 13,063,710\n",
      "Trainable params: 13,060,710\n",
      "Non-trainable params: 3,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 1.6885 - accuracy: 0.4198 - val_loss: 2.9300 - val_accuracy: 0.1000\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 1.2043 - accuracy: 0.5699 - val_loss: 1.4805 - val_accuracy: 0.4498\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 1.0171 - accuracy: 0.6377 - val_loss: 0.9595 - val_accuracy: 0.6617\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.9064 - accuracy: 0.6777 - val_loss: 0.8554 - val_accuracy: 0.7085\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.8273 - accuracy: 0.7082 - val_loss: 1.2501 - val_accuracy: 0.6052\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.7704 - accuracy: 0.7291 - val_loss: 0.7395 - val_accuracy: 0.7375\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.7179 - accuracy: 0.7460 - val_loss: 0.7454 - val_accuracy: 0.7392\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.6749 - accuracy: 0.7641 - val_loss: 0.6875 - val_accuracy: 0.7645\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.6405 - accuracy: 0.7758 - val_loss: 0.6609 - val_accuracy: 0.7738\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.6136 - accuracy: 0.7842 - val_loss: 0.6904 - val_accuracy: 0.7717\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.5813 - accuracy: 0.7961 - val_loss: 0.7542 - val_accuracy: 0.7480\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.5515 - accuracy: 0.8058 - val_loss: 0.6310 - val_accuracy: 0.7911\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.5296 - accuracy: 0.8158 - val_loss: 0.5517 - val_accuracy: 0.8096\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.5102 - accuracy: 0.8216 - val_loss: 0.5780 - val_accuracy: 0.8076\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4926 - accuracy: 0.8270 - val_loss: 0.5685 - val_accuracy: 0.8114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f884c550b70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(full_x_train, full_y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(full_x_train)//batch_size,\n",
    "                        validation_data=(full_x_test, full_y_test),\n",
    "                        epochs=epochs, verbose=1, workers=20,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 138us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(full_x_test, full_y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5684614914655686, 0.8113999962806702]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense = Sequential()\n",
    "#model_dense.add(Input(shape=(32,32,3)))\n",
    "model_dense.add(Flatten(input_shape=(32,32,3)))\n",
    "\n",
    "\n",
    "model_dense.add(Dropout(0.125))\n",
    "model_dense.add(Dense(2000))\n",
    "model_dense.add(Dropout(0.25))\n",
    "model_dense.add(Dense(10, activation=\"softmax\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000)              6146000   \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 6,166,010\n",
      "Trainable params: 6,166,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.SGD(lr=0.001),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 2.6325 - accuracy: 0.1981 - val_loss: 1.9878 - val_accuracy: 0.3116\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 2.4055 - accuracy: 0.2398 - val_loss: 1.9059 - val_accuracy: 0.3410\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.3514 - accuracy: 0.2498 - val_loss: 1.8683 - val_accuracy: 0.3470\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.3031 - accuracy: 0.2578 - val_loss: 1.8419 - val_accuracy: 0.3631\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 2.2680 - accuracy: 0.2613 - val_loss: 1.8249 - val_accuracy: 0.3702\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 2.2425 - accuracy: 0.2650 - val_loss: 1.8155 - val_accuracy: 0.3688\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 2.2206 - accuracy: 0.2726 - val_loss: 1.8036 - val_accuracy: 0.3733\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 2.1935 - accuracy: 0.2741 - val_loss: 1.7952 - val_accuracy: 0.3760\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 2.1749 - accuracy: 0.2783 - val_loss: 1.7881 - val_accuracy: 0.3813\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.1567 - accuracy: 0.2808 - val_loss: 1.7815 - val_accuracy: 0.3835\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.1422 - accuracy: 0.2819 - val_loss: 1.7776 - val_accuracy: 0.3909\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 2.1352 - accuracy: 0.2833 - val_loss: 1.7744 - val_accuracy: 0.3892\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.1175 - accuracy: 0.2878 - val_loss: 1.7671 - val_accuracy: 0.3917\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 2.1078 - accuracy: 0.2890 - val_loss: 1.7670 - val_accuracy: 0.3908\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 2.0993 - accuracy: 0.2914 - val_loss: 1.7607 - val_accuracy: 0.3935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f882d906940>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dense.fit_generator(datagen.flow(full_x_train, full_y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(full_x_train)//batch_size,\n",
    "                        validation_data=(full_x_test, full_y_test),\n",
    "                        epochs=epochs, verbose=1, workers=20,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 80us/step\n"
     ]
    }
   ],
   "source": [
    "scores_dense = model_dense.evaluate(full_x_test, full_y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7607048892974853, 0.3935000002384186]\n"
     ]
    }
   ],
   "source": [
    "print(scores_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For images and video processing, advantages of CNN over MLP constitute in:\n",
    "- ability to extract spacial features (in a \"natural\" way, with a sliding window)\n",
    "- shift robustness\n",
    "- lower complexity (for larger images)\n",
    "- tranferrability to different image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nshvai",
   "language": "python",
   "name": ".nshvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
